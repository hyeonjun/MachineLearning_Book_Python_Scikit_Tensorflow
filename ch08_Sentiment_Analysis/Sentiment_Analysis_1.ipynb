{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch08_Sentiment_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/E2ISHmi677ScjkjCiuYJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 8. 감성 분석에 머신러닝 적용\n",
        "\n",
        "# 8.1 텍스트 처리용 IMDb 영화 리뷰 데이터 준비\n",
        "\n",
        "### 8.1.1 영화 리뷰 데이터셋 구하기\n",
        "\n",
        "IMDB 영화 리뷰 데이터셋은 [http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)에서 내려받을 수 있다. 다운로드된 후 파일 압축을 해제한다.\n",
        "\n",
        "A) 리눅스(Linux)나 macOS를 사용하면 새로운 터미널(Terminal) 윈도우를 열고 `cd` 명령으로 다운로드 디렉터리로 이동하여 다음 명령을 실행. \n",
        "\n",
        "`tar -zxf aclImdb_v1.tar.gz`\n",
        "\n",
        "B) 윈도(Windows)를 사용하면 7-Zip(http://www.7-zip.org) 같은 무료 압축 유틸리티를 설치하여 다운로드한 파일의 압축을 풀 수 있다."
      ],
      "metadata": {
        "id": "3iYafDxwjdcs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "53dDdR_HgFr-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "import time\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "source = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "target = 'aclImdb_v1.tar.gz'\n",
        "\n",
        "\n",
        "def reporthook(count, block_size, total_size):\n",
        "    global start_time\n",
        "    if count == 0:\n",
        "        start_time = time.time()\n",
        "        return\n",
        "    duration = time.time() - start_time\n",
        "    progress_size = int(count * block_size)\n",
        "    speed = progress_size / (1024.**2 * duration)\n",
        "    percent = count * block_size * 100. / total_size\n",
        "\n",
        "    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed\" %\n",
        "                    (percent, progress_size / (1024.**2), speed, duration))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "if not os.path.isdir('aclImdb') and not os.path.isfile('aclImdb_v1.tar.gz'):\n",
        "    urllib.request.urlretrieve(source, target, reporthook)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gzip 압축된 타볼 파일의 압축을 풀 수 있다.\n",
        "if not os.path.isdir('aclImdb'):\n",
        "\n",
        "    with tarfile.open(target, 'r:gz') as tar:\n",
        "        tar.extractall()"
      ],
      "metadata": {
        "id": "QrpRNThlkBnV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1.2 영화 리뷰 데이터셋을 더 간편한 형태로 전처리\n",
        "\n",
        "데이터셋의 압축을 푼 후 압축이 풀린 개개의 텍스트 문서를 하나의 CSV 파일로 합친다. 영화 리뷰를 읽어 하나의 판다스 DataFrame 객체로 만든다."
      ],
      "metadata": {
        "id": "PStig7JBkIHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyprind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfNesoWYkztU",
        "outputId": "df373c00-116d-4fe4-fbcb-147178e3f41c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.7/dist-packages (2.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyprind\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# `basepath`를 압축 해제된 영화 리뷰 데이터셋이 있는 디렉토리로 바꾼다.\n",
        "basepath = 'aclImdb'\n",
        "\n",
        "labels = {'pos': 1, 'neg': 0} # 정수 클래스 레이블 (1=긍정, 0=부정)\n",
        "pbar = pyprind.ProgBar(50000) # 읽어들일 문서 개수\n",
        "df = pd.DataFrame()\n",
        "for s in ('test', 'train'): # aclImdb 디렉터리의 하위 디렉터리 train, test\n",
        "    for l in ('pos', 'neg'): # 그 아래 pos와 neg 디렉터리에서\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in sorted(os.listdir(path)):\n",
        "            with open(os.path.join(path, file),  # 개별 텍스트 파일을 읽는다\n",
        "                      'r', encoding='utf-8') as infile:\n",
        "                txt = infile.read()\n",
        "            df = df.append([[txt, labels[l]]], \n",
        "                           ignore_index=True)\n",
        "            pbar.update()\n",
        "df.columns = ['review', 'sentiment']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzx_pu2pk1aV",
        "outputId": "65d83923-c531-45d8-ca01-1af0ba868f9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합친 데이터셋의 클래스 레이블이 순서대로 나열되어 있다. np.random 모듈의 permutation 함수를 사용하여 이 데이터프레임을 섞는다."
      ],
      "metadata": {
        "id": "1I4qe1jAnZpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv('movie_data.csv', index=False, encoding='utf-8')\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "n23aNeyYni7K",
        "outputId": "5ae81731-bfc0-4b29-da13-cacba087a8a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ec4a56fe-319b-466a-9b30-1e62f06b3632\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11841</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19602</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45519</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec4a56fe-319b-466a-9b30-1e62f06b3632')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec4a56fe-319b-466a-9b30-1e62f06b3632 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec4a56fe-319b-466a-9b30-1e62f06b3632');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "11841  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "19602  OK... so... I really like Kris Kristofferson a...          0\n",
              "45519  ***SPOILER*** Do not read this, if you think a...          0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "VO7xs9adz3tw",
        "outputId": "416c9aa0-0941-4719-8192-cd5defa92915"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0f5cf894-4efc-4efa-a4be-ff25dba08802\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f5cf894-4efc-4efa-a4be-ff25dba08802')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f5cf894-4efc-4efa-a4be-ff25dba08802 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f5cf894-4efc-4efa-a4be-ff25dba08802');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xq3UuZvn23j",
        "outputId": "aea981c5-738f-4974-b2cc-b41336329760"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 BoW 모델 소개\n",
        "1. 전체 문서에 대해 고유한 토큰, 예를 들어 단어로 이루어진 어휘 사전을 만든다.\n",
        "2. 특정 문서에 각 단어가 얼마나 자주 등장하는지 헤어려 문서의 특성 벡터를 만든다\n",
        "* 각 문서에 있는 고유한 단어는 BoW 어휘 사전에 있는 모든 단어의 일부분에 지나지 않으므로 특성 벡터는 대부분 0으로 채워진다.\n",
        "    * **희소 행렬**\n",
        "\n",
        "### 8.2.1 단어를 특정 벡터로 변환\n",
        "* 사이킷런 CountVectorizer 클래스 - 각각의 문서에 있는 단어 카운트 기반으로 BoW 모델 구현\n"
      ],
      "metadata": {
        "id": "YHaK8Xuhn7j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "docs = np.array([\n",
        "        'The sun is shining',\n",
        "        'The weather is sweet',\n",
        "        'The sun is shining, the weather is sweet, and one and one is two'])\n",
        "bag = count.fit_transform(docs)"
      ],
      "metadata": {
        "id": "fZ70yXO5onMr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 어휘 사전 내용 - 고유 단어와 정수 인덱스\n",
        "count.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdummehQo9u0",
        "outputId": "823779b4-c3fa-40b4-d816-7607df13a7aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 0,\n",
              " 'is': 1,\n",
              " 'one': 2,\n",
              " 'shining': 3,\n",
              " 'sun': 4,\n",
              " 'sweet': 5,\n",
              " 'the': 6,\n",
              " 'two': 7,\n",
              " 'weather': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "특성 벡터의 각 인덱스는 CountVectorizer의 어휘 사전 딕셔너리에 저장된 정수 값에 해당된다. 예를 들어 인덱스 0에 있는 첫 번째 특성은 ‘and’ 단어의 카운트를 의미한다. 인덱스 1에 있는 (특성 벡터의 두 번째 열) 단어 ‘is’는 세 문장에 모두 등장한다. 특성 벡터의 이런 값들을 단어 빈도(term frequency) 라고도 부른다. 문서 d에 등장한 단어 t의 횟수를 *tf (t,d)*와 같이 쓴다."
      ],
      "metadata": {
        "id": "LtEvIL1LsuoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bag.toarray())\n",
        "\n",
        "\"\"\"\n",
        "[[0 1 0 1 1 0 1 0 0]   : and=0, is=1, one=0, shining=1, sun=1, sweet=0, the=1, two=0, weather=0\n",
        " [0 1 0 0 0 1 1 0 1]\n",
        " [2 3 2 1 1 1 2 1 1]]\n",
        " \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "el3EXPdnpC4S",
        "outputId": "58a63c7e-bb98-4079-f017-23cb0d24a489"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 1 1 0 1 0 0]\n",
            " [0 1 0 0 0 1 1 0 1]\n",
            " [2 3 2 1 1 1 2 1 1]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n[[0 1 0 1 1 0 1 0 0]   : and=0, is=1, one=0, shining=1, sun=1, sweet=0, the=1, two=0, weather=0\\n [0 1 0 0 0 1 1 0 1]\\n [2 3 2 1 1 1 2 1 1]]\\n '"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.2 tf-idf를 사용하여 단어 적합성 평가\n",
        "* 특정 벡터에서 자주 등장하는 단어의 가중치를 낮추는 기법\n",
        "* tf-idf는 단어 빈도와 역문서 빈도(inverse document frequency)의 곱으로 정의\n",
        "\n",
        "$$\\text{tf-idf}(t,d)=\\text{tf (t,d)}\\times \\text{idf}(t,d)$$\n",
        "\n",
        "* tf(t, d)는 단어 빈도, idf(t, d)는 역분서 빈도.\n",
        "\n",
        "$$\\text{idf}(t,d) = \\text{log}\\frac{n_d}{1+\\text{df}(d, t)},$$\n",
        "\n",
        "$n_d$는 전체 문서 개수이고, df(d, t)는 단어 t가 포함된 문서의 d의 개수이다. 분모에 상수 1을 추가하는 것은 선택 사항으로, 훈련 샘플에 한 번도 등장하지 않는 단어가 있는 경우 분모가 0이 되지 않게 만든다. log는 문서 빈도 df(d, t)가 낮을 때 역문서 빈도 값이 너무 커지지 않도록 만든다.\n",
        "\n",
        "* 사이킷런 CountVectorizer 클래스에서 만든 단어 빈도를 입력받아 TfidfTransformer 클래스를 사용하여 tf-idf로 변환.\n",
        "\n"
      ],
      "metadata": {
        "id": "XmSoGugmo7ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
        "np.set_printoptions(precision=2)\n",
        "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocAxYrh9vUpZ",
        "outputId": "35d86e95-d96f-4f98-e5ef-07bce1989810"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]\n",
            " [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]\n",
            " [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer에서 확인한 단어 빈도에서는 'is'가 가장 많이 나타났었다. 동일한 특성 벡터를 tf-idf로 변환하면 단어 'is'는 비교적 작은 tf-idf를 가진다(0.45). 이 단어는 첫 번째와 두 번째 문서에도 나타나므로 판별에 유용한 정보를 가지고 있지 않을 것이다."
      ],
      "metadata": {
        "id": "A31MscbBv0mZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "수동으로 특성 벡터에 있는 각 단어의 tf-idf를 계산해보면 `TfidfTransformer`가 위에서 정의한 표준 tf-idf 공식과 조금 다르게 계산된다. \n",
        "* 사이킷런에 구현된 역문서 빈도 공식\n",
        "\n",
        "$$\\text{idf} (t,d) = log\\frac{1 + n_d}{1 + \\text{df}(d, t)}$$\n",
        "\n",
        "* 사이킷런 tf-idf 공식\n",
        "\n",
        "$$\\text{tf-idf}(t,d) = \\text{tf}(t,d) \\times (\\text{idf}(t,d)+1)$$\n",
        "\n",
        "'+1'을 더한 것은 모든 문서에 등장하는 단어가 가중치 0이 되는 것(즉, idf(t, d)=log(1)=0)을 막기 위해서이다.\n",
        "\n",
        "일반적으로 tf-idf를 계산하기 전에 단어 빈도(tf)를 정규화하지만 `TfidfTransformer` 클래스는 tf-idf를 직접 정규화한다. 사이킷런의 TfidfTransformer는 기본적으로 L2 정규화를 적용(norm='l2'). 정규화되지 않은 특성 벡터 v를 L2로 나누면 길이가 1인 벡터가 반환된다.\n",
        "\n",
        "$$v_{\\text{norm}} = \\frac{v}{||v||_2} = \\frac{v}{\\sqrt{v_{1}^{2} + v_{2}^{2} + \\dots + v_{n}^{2}}} = \\frac{v}{\\big (\\sum_{i=1}^{n} v_{i}^{2}\\big)^\\frac{1}{2}}$$\n",
        "\n",
        "$\\text{idf}(\"is\", d3) = log \\frac{1+3}{1+3} = 0$\n",
        "\n",
        "$\\text{tf-idf}(\"is\",d3)= 3 \\times (0+1) = 3$"
      ],
      "metadata": {
        "id": "C5lrzTFpwHmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_is = 3\n",
        "n_docs = 3\n",
        "idf_is = np.log((n_docs+1) / (3+1))\n",
        "tfidf_is = tf_is * (idf_is + 1)\n",
        "print('idf \"is\" = %d' % idf_is)\n",
        "print('tf-idf of term \"is\" = %.2f' % tfidf_is)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSHC3mYVxc5a",
        "outputId": "d9968f07-d021-44af-b60f-2b6ae20d5164"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idf \"is\" = 0\n",
            "tf-idf of term \"is\" = 3.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "세 번째 문서에 있는 모든 단어에 대해 이런 계산을 반복하면 tf-idf 벡터 [3.39, 3.0, 3.39, 1.29, 1.29, 1.29, 2.0, 1.69, 1.29]를 얻는다. 이 특성 벡터의 값은 앞서 사용했던 TfidfTransformer에서 얻은 값과 다르다. tf-idf 계산에서 빠트린 마지막 단계는 다음과 같은 L2-정규화이다.\n",
        "\n",
        "$$\\text{tfi-df}_{norm} = \\frac{[3.39, 3.0, 3.39, 1.29, 1.29, 1.29, 2.0 , 1.69, 1.29]}{\\sqrt{[3.39^2, 3.0^2, 3.39^2, 1.29^2, 1.29^2, 1.29^2, 2.0^2 , 1.69^2, 1.29^2]}}$$\n",
        "\n",
        "$$=[0.5, 0.45, 0.5, 0.19, 0.19, 0.19, 0.3, 0.25, 0.19]$$\n",
        "\n",
        "$$\\Rightarrow \\text{tfi-df}_{norm}(\"is\", d3) = 0.45$$"
      ],
      "metadata": {
        "id": "DEQrsvQ4xr4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfTransformer(use_idf=True, norm=None, smooth_idf=True)\n",
        "raw_tfidf = tfidf.fit_transform(count.fit_transform(docs)).toarray()[-1]\n",
        "l2_tfidf = raw_tfidf / np.sqrt(np.sum(raw_tfidf**2))\n",
        "print(raw_tfidf)\n",
        "print('= {0}'.format(l2_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTOjFxKQx02D",
        "outputId": "469df4ae-eeb4-4a41-9723-2361c0e6f6ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.39 3.   3.39 1.29 1.29 1.29 2.   1.69 1.29]\n",
            "= [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.3 텍스트 데이터 정제"
      ],
      "metadata": {
        "id": "e8PvNkFQyKL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0, 'review'][-50:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k83eJ41lyQDY",
        "outputId": "abc6ed15-aab6-4958-b180-319b89d003c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'is seven.<br /><br />Title (Brazil): Not Available'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HTML 마크업은 구두점과 글자가 아닌 문자가 포함되어 있다. HTML 마크업에는 유용한 의미가 많지 않지만 구두점은 특정 NLP 문제에서 쓸모있는 추가 정보가 될 수 있다. \n",
        "\n",
        "간단하게 하기위해 :) 와 같은 이모티콘 문자를 제외하고 모든 구두점 기호를 삭제한다. 이런 이모티콘은 확실히 감성 분석에 유용하다. "
      ],
      "metadata": {
        "id": "p4jjl37v0LbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text) # 모든 HTML 마크업 삭제\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text) # 마크업을 제거한 후 이모티콘을 찾아 저장\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')) # 텍스트를 소문자로 바꾸고 [\\W]+를 사용하여 텍스트에서 단어가 아닌 문자를 모두 제거\n",
        "    return text"
      ],
      "metadata": {
        "id": "cIcKXOLF0GtI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(df.loc[0, 'review'][-50:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7B4zeur92Kwh",
        "outputId": "059f72fe-b533-49d3-f762-215681af1b8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'is seven title brazil not available'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"</a>This :) is :( a test :-)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "shP-CfuG2Pbg",
        "outputId": "67187929-55b9-45ef-8d6f-c4b28bc090b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is a test :) :( :)'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(preprocessor)"
      ],
      "metadata": {
        "id": "M7vozQy92RWc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 문서를 토큰으로 나누기\n",
        "\n",
        "영화 리뷰 데이터셋을 전처리한 후에는 어떻게 텍스트 문서를 낱개의 토큰으로 나눌지 생각해야 한다. 문서를 토큰화하는 한 가지 방법은 공백 문자를 기준으로 개별 단어로 나누는 것이다."
      ],
      "metadata": {
        "id": "nUtpcUY-2sEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "tokenizer('runners like running and thus they run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebq1aBGr281o",
        "outputId": "889d35d3-3efb-4590-80fc-b8249d0ab1bb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화 방법 중에는 단어는 변하지 않는 기본 형태인 어간으로 바꾸는 **어간 추출**(stemming)이란 방법이 있다. 여러 가지 형태를 갖는 단어를 같은 어간으로 매핑할 수 있다. 초기 어간 추출 알고리즘은 포터 어간 추출기 알고리즘이라고 한다.\n",
        "\n",
        "파이썬의 **NLTK** 패키지 - 어간 추출 알고리즘"
      ],
      "metadata": {
        "id": "_GAH7ieX3D5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 포터 어간 추출 알고리즘\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "tokenizer_porter('runners like running and thus they run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fon1FKtp4Hxw",
        "outputId": "1f04a926-2dd9-45d5-c6af-90da3ad59b2b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk 패키지의 PorterStemmer 클래스를 사용하여 단어의 어간으로 바꾸기 위해 tokenizer 함수를 변경했다. 이전 'running'이 어간 'run'으로 바뀌었다."
      ],
      "metadata": {
        "id": "B1B-qkBR4m-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 불용어(stop-word) 제거\n",
        "    * 불용어 : 모든 종류의 텍스트에 아주 흔하게 등장하는 단어로, 'is', 'and', 'has', 'like' 등이 있다. \n",
        "    * tf-idf보다 기본 단어 빈도나 정규화된 단어 빈도를 사용할 때 유용하다."
      ],
      "metadata": {
        "id": "mcfN990o5Cog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# 불용어 제거를 위해 NLTK 라이브러리에서 제공하는 179개의 불용어를 사용한다.\n",
        "# 이 불용어는 nltk.download 함수를 호출하여 내려받는다.\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2sk6xpy5gtv",
        "outputId": "eaa98c0b-0a41-4c5b-c21b-30c9b3173b9a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 집합을 내려받은 후 영어의 불용어를 불러들여 적용\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:] if w not in stop]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZlIVAoz5xBO",
        "outputId": "ad32c77f-4872-4e83-d3e1-c6486f814875"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'run', 'lot']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.3 문서 분류를 위한 로지스틱 회귀 모델 훈련\n",
        "\n",
        "BoW 모델을 기반으로 영화 리뷰를 긍정과 부정 리뷰로 분류하는 로지스틱 회귀 모델을 훈련시킨다. 먼저 정제된 텍스트 문서가 저장된 DataFrame을 25,000개는 훈련 데이터셋으로 나누고 25,000개는 테스트 데이터셋으로 나눈다."
      ],
      "metadata": {
        "id": "T-JHp4Kx6VHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df.loc[:25000, 'review'].values\n",
        "y_train = df.loc[:25000, 'sentiment'].values\n",
        "X_test = df.loc[25000:, 'review'].values\n",
        "y_test = df.loc[25000:, 'sentiment'].values"
      ],
      "metadata": {
        "id": "DIxPn-Sm7c3n"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV 객체에서 5-겹 계층별 교차 검증을 사용하여 로지스틱 회귀 모델에 대한 최적 매개변수 조합을 찾는다\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# TfidfVectorizer : CountVectorizer와 TfidfTransformer를 하나로 합침\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None) \n",
        "\n",
        "# 첫번째는 TfidfVectorizer의 기본 매개변수 셋팅(use_idf=True, norm='l2')을 사용하여 tf-idf 께산\n",
        "# 두번째는 단어 빈도를 사용하여 모델을 훈련 시키기 위해 use_idf=False, norm=None 으로 설정\n",
        "# 로지스틱 회귀 분류기는 penaly 매개변수를 통해 L1과 L2 규제를 적용하고,\n",
        "# 규제 매개변수 C에 여러 값을 지정해 규제 강도를 비교\n",
        "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
        "               'vect__stop_words': [stop, None],\n",
        "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "               'clf__penalty': ['l1', 'l2'],\n",
        "               'clf__C': [1.0, 10.0, 100.0]},\n",
        "              {'vect__ngram_range': [(1, 1)],\n",
        "               'vect__stop_words': [stop, None],\n",
        "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "               'vect__use_idf':[False],\n",
        "               'vect__norm':[None],\n",
        "               'clf__penalty': ['l1', 'l2'],\n",
        "               'clf__C': [1.0, 10.0, 100.0]},\n",
        "              ]\n",
        "\n",
        "lr_tfidf = Pipeline([('vect', tfidf),\n",
        "                     ('clf', LogisticRegression(random_state=0, solver='liblinear'))])\n",
        "\n",
        "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='accuracy', cv=5, n_jobs=-1)"
      ],
      "metadata": {
        "id": "xUgPnwQc7lgm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* n_jobs 매개변수\n",
        "\n",
        "컴퓨터에 있는 모든 CPU 코어를 사용해 그리드 서치의 속도를 높이려면 (`n_jobs=1` 대신) `n_jobs=-1`로 지정하는 것이 좋다. 일부 시스템에서는 멀티프로세싱을 위해 `n_jobs=-1`로 지정할 때 `tokenizer` 와 `tokenizer_porter` 함수의 직렬화에 문제가 발생할 수 있다. 이런 경우 `[tokenizer, tokenizer_porter]`를 `[str.split]`로 바꾸어 문제를 해결할 수 있다. 다만 `str.split`로 바꾸면 어간 추출을 하지 못한다."
      ],
      "metadata": {
        "id": "s7V7tf699doS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**코랩을 사용할 경우에도 CPU 코어가 많지 않기 때문에 실행 시간이 오래 걸릴 수 있습니다.**\n",
        "\n",
        "너무 오래 기다리기 어렵다면 데이터셋의 훈련 샘플의 수를 다음처럼 줄일 수 있습니다:\n",
        "\n",
        "    X_train = df.loc[:2500, 'review'].values\n",
        "    y_train = df.loc[:2500, 'sentiment'].values\n",
        "    \n",
        "훈련 세트 크기를 줄이는 것은 모델 성능을 감소시킵니다. 그리드에 지정한 매개변수를 삭제하면 훈련한 모델 수를 줄일 수 있습니다. 예를 들면 다음과 같습니다:\n",
        "\n",
        "    param_grid = [{'vect__ngram_range': [(1, 1)],\n",
        "                   'vect__stop_words': [stop, None],\n",
        "                   'vect__tokenizer': [tokenizer],\n",
        "                   'clf__penalty': ['l1', 'l2'],\n",
        "                   'clf__C': [1.0, 10.0]},\n",
        "                  ]"
      ],
      "metadata": {
        "id": "S_Mt9CyP90sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gs_lr_tfidf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqg1Wogy9vR9",
        "outputId": "e09123bb-a89c-4690-90d5-a0146f24985f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        TfidfVectorizer(lowercase=False)),\n",
              "                                       ('clf',\n",
              "                                        LogisticRegression(random_state=0,\n",
              "                                                           solver='liblinear'))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'clf__C': [1.0, 10.0, 100.0],\n",
              "                          'clf__penalty': ['l1', 'l2'],\n",
              "                          'vect__ngram_range': [(1, 1)],\n",
              "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
              "                                                'our', 'ours', 'ourselves',\n",
              "                                                'you', \"you're\", \"you've...\n",
              "                                                'our', 'ours', 'ourselves',\n",
              "                                                'you', \"you're\", \"you've\",\n",
              "                                                \"you'll\", \"you'd\", 'your',\n",
              "                                                'yours', 'yourself',\n",
              "                                                'yourselves', 'he', 'him',\n",
              "                                                'his', 'himself', 'she',\n",
              "                                                \"she's\", 'her', 'hers',\n",
              "                                                'herself', 'it', \"it's\", 'its',\n",
              "                                                'itself', ...],\n",
              "                                               None],\n",
              "                          'vect__tokenizer': [<function tokenizer at 0x7f208f3c0170>,\n",
              "                                              <function tokenizer_porter at 0x7f208f3c0ef0>],\n",
              "                          'vect__use_idf': [False]}],\n",
              "             scoring='accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적의 매개변수 조합: %s ' % gs_lr_tfidf.best_params_)\n",
        "\n",
        "# 그리드 서치로 찾은 최상의 모델을 사용하여 훈련 데이터셋에 대한 모델의 5-겹 교차 검증 정확도와\n",
        "# 테스트 데이터셋에 대한 분류 정확도를 출력\n",
        "print('CV 정확도: %.3f' % gs_lr_tfidf.best_score_)\n",
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print('테스트 정확도: %.3f' % clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnLZx02o9379",
        "outputId": "da7857ab-4564-4229-b89c-a9624c85f847"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 매개변수 조합: {'clf__C': 10.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f208f3c0170>} \n",
            "CV 정확도: 0.897\n",
            "테스트 정확도: 0.899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### k-폴드 교차 검증과 GridSearchCV 객체\n",
        "\n",
        "k-폴드 교차 검증으로 GridSearchCV 객체를 훈련하면 `best_score_` 속성은 최상의 모델에 대한 k-폴드 점수의 평균을 반환한다."
      ],
      "metadata": {
        "id": "JGnD-lY7Aa21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(0)\n",
        "np.set_printoptions(precision=6)\n",
        "y = [np.random.randint(3) for i in range(25)]\n",
        "X = (y + np.random.randn(25)).reshape(-1, 1)\n",
        "\n",
        "cv5_idx = list(StratifiedKFold(n_splits=5, shuffle=False).split(X, y))\n",
        "    \n",
        "lr = LogisticRegression(random_state=123, multi_class='ovr', solver='lbfgs')\n",
        "cross_val_score(lr, X, y, cv=cv5_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud1GsG1-Arpl",
        "outputId": "11b1ee89-b84a-42f4-d655-3732c875ff33"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4, 0.2, 0.6, 0.2, 0.4])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "클래스 레이블에 해당하는 랜덤한 정수 데이터셋이 만들어진다. 그 다음 5-폴드의 인덱스(`cv5_idx`)를 cross_val_score 함수에 전달하여 5개의 정확도 점수를 받는다. 이 점수가 다섯 개의 테스트 폴드에 대한 정확도 값이다.\n",
        "\n",
        "그 다음 `GridSearchCV` 객체를 사용해 동일한 5-폴드 인덱스(`cv5_idx`)를 전달."
      ],
      "metadata": {
        "id": "fD1FiJt8AtBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "lr = LogisticRegression(solver='lbfgs', multi_class='ovr', random_state=1)\n",
        "gs = GridSearchCV(lr, {}, cv=cv5_idx, verbose=3).fit(X, y) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiZLNfLABI8M",
        "outputId": "30f0ff28-c155-44b2-e719-46dafdcaf23d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END ..................................., score=0.400 total time=   0.0s\n",
            "[CV 2/5] END ..................................., score=0.200 total time=   0.0s\n",
            "[CV 3/5] END ..................................., score=0.600 total time=   0.0s\n",
            "[CV 4/5] END ..................................., score=0.200 total time=   0.0s\n",
            "[CV 5/5] END ..................................., score=0.400 total time=   0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-폴드에 대한 점수는 `cross_val_score`에서 얻은 것과 일치.\n",
        "\n",
        "이제 fit 메서드를 호출한 후의 GridSearchCV 객체의 best_score_ 속성은 최상의 모델의 평균 정확도를 반환한다."
      ],
      "metadata": {
        "id": "Lf5plPZBBKK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(gs.best_score_)\n",
        "\n",
        "lr = LogisticRegression(solver='lbfgs', multi_class='ovr', random_state=1)\n",
        "print(cross_val_score(lr, X, y, cv=cv5_idx).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z28xSbGHBXHF",
        "outputId": "b8191cbc-9011-4daa-de31-9844f719241b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.36000000000000004\n",
            "0.36000000000000004\n"
          ]
        }
      ]
    }
  ]
}