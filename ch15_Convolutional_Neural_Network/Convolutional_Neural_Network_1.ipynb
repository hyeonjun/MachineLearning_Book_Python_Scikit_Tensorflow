{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch15_Convolutional_Neural_Network_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/eJwu+7QcJckag6fJLpAD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "HGxnFtjnIzPR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. 심층 합성곱 신경망으로 이미지 분류\n",
        "* 1차원과 2차원의 합성곱 연산\n",
        "* CNN 구조의 구성 요소\n",
        "* 텐서플로를 사용하여 심층 합성곱 신경망 구현\n",
        "* 일반화 성능 향상을 위한 데이터 증식\n",
        "* 얼굴 이미지에서 성별을 예측하는 합성곱 신경망 구현"
      ],
      "metadata": {
        "id": "WPYDi3MmIccF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15.1 합성곱 신경망의 구성 요소\n",
        "\n",
        "### 15.1.1 CNN과 특성 계층 학습\n",
        "CNN과 같은 종류의 신경망은 원본 데이터에서 작업에 가장 유용한 특성을 자동으로 학습할 수 있다. 이런 이유로 CNN 층을 특성 추출기로 생각하기도 한다. (입력층 바로 다음에 있는) 층은 원본 데이터에서 저수준 특성을 추출한다. (종종 다층 퍼셉트론(MLP)과 같은 완전 연결 층으로 만드는) 뒤쪽의 층은 이런 특성을 사용하여 연속적인 타깃 값이나 클래스 레이블을 예측한다.\n",
        "\n",
        "특정 종류의 다층 신경망과 특히 심층 합성곱 신경망은 각 층별로 저수준 특성을 연결하여 고수준 특성을 만듦으로써 소위 특성 계층을 구성한다. 예를 들어 이미지를 다룬다면 모서리나 동그라미 같은 저수준 특성이 앞쪽 층에서 추출된다. 이 특성들이 연결되어 고수준 특성을 형성한다. 이런 고수준 특성은 건물, 자동차, 강아지 같은 더 복잡한 모양을 형성할 수 있다.\n",
        "\n",
        "CNN은 입력 이미지에서 **특성 맵**(feature map)을 만든다. 이 맵의 각 원소는 입력 이미지의 국부적인 픽셀 패치에서 유도된다."
      ],
      "metadata": {
        "id": "iJ3Ux_GZIzzr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "34SFgxrsIQ0l",
        "outputId": "f820a679-203b-40e0-8a51-5d61ab6227c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5O3\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# 언스플래시(Unsplash)에 있는 알렉산더 더머의 사진\n",
        "Image(url='https://git.io/JL5O3', width=700)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이러한 국부적인 픽셀 패치를 국부 수용장이라고 말한다.\n",
        "\n",
        "* CNN의 아이디어\n",
        "    * 희소 연결: 특성 맵에 있는 하나의 원소는 작은 픽셀 패치 하나에만 연결\n",
        "    * 파라미터 공유: 동일한 가중치가 입력 이미지의 모든 패치에 사용\n",
        "\n",
        "CNN은 여러 개의 합성곱(conv) 층과 풀링(Pooling, P)이라고도 하는 서브샘플링(subsampling) 층으로 이루어져 있다. 마지막에는 하나 이상의 완전 연결(FC) 층이 따라온다. 완전 연결 층은 모든 입력 유닛 i가 모든 출력 유닛 j에 가중치 $w_{ij}$로 연결되어 있는 다층 퍼셉트론이다.\n",
        "\n",
        "* 서브샘플링 층(풀링 층)\n",
        "    * 학습되는 파라미터가 없다.\n",
        "        * 풀링 층에 가중치나 절편 유닛이 없다.\n",
        "* 합성곱이나 완전 연결 층은 훈련 도중 최적화되는 가중치와 절편을 가진다.    "
      ],
      "metadata": {
        "id": "lZF0xT4RLrBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.1.2 이산 합성곱 수행\n",
        "* 이산 합성곱(discrete convolution, 합성곱)\n",
        "    * CNN의 기본 연산\n",
        "\n",
        "* 1차원 이산 합성곱 연산 수행\n",
        "    * 두 개의 벡터 x와 w에 대한 이산 합성곱은 y = x * w\n",
        "        * x: 입력(신호)\n",
        "        * w: 필터 또는 커널\n",
        "\n",
        "\n",
        "$y=x*w$ -> $y[i] = \\sum_{k=-∞}^{+∞}x[i-k]w[k]$\n",
        "\n",
        "1. 인덱스 -∞부터 +∞까지의 합\n",
        "    * 머신러닝 애플리케이션은 항상 유한한 특성 벡터를 다룬다.\n",
        "        * ex, x가 0, 1, 2, ..., 8, 9 인덱스로 열 개의 특성을 가지고 있다면 -∞:-1과 10:+∞ 인덱스는 x의 범위 밖이다. 덧셈을 올바르게 하려면 x와 w가 0으로 채워져 있다고 가정해야 한다. 또한, 출력 벡터 y도 0으로 채워진 무한 크기가 된다.\n",
        "        * 실제 상황에서는 유용하지 않기 때문에 유한한 개수의 0으로 x가 **패딩**된다.\n",
        "    * **제로 패딩** 또는 **패딩**\n",
        "        * p: 각 방향으로 추가된 패딩 수"
      ],
      "metadata": {
        "id": "G41enfovNZ7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원 패딩 예\n",
        "Image(url='https://git.io/JL5On', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "U5xFb2AwNY-c",
        "outputId": "cf812937-4f45-4415-b10d-2ae08f8ddff6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5On\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본 입력 x와 필터 w가 각각 n개, m개의 원소를 가지고 있고 m <= n 이라고 가정. 패딩된 벡터 $x^p$ 크기는 n + 2p 이다.\n",
        "\n",
        "$y = x * w$ -> $y[i] = \\sum_{k=0}^{k=m-1}x^p[i+m-k]w[k]$\n",
        "\n",
        "2. i+m-k로 x 인덱싱\n",
        "    * x와 w가 다른 방향으로 인덱싱.\n",
        "        * 하나가 반대 방향으로 인덱싱되는 계산은 패딩된 후 x 또는 w 벡터 중 하나를 뒤집어 계산하는 것과 동일.\n",
        "        * 필터 w를 뒤집어서 회전된 필터 $w^r$를 얻었다고 가정.\n",
        "        * 점곱 x[i:i+m]*$w^r$을 계산하면 y[i] 원소 하나가 얻어진다.\n",
        "            * x[i:i+m]은 크기가 m인 x의 패치.\n",
        "            * 이 연산은 모든 출력 원소를 얻기 위해 슬라이딩 윈도우 방식으로 반복"
      ],
      "metadata": {
        "id": "LD1SoetIR8-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원 합성곱\n",
        "Image(url='https://git.io/JL5O8', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "BvEcBMF3TCo9",
        "outputId": "b79d11d7-6a2f-4550-8f94-49b16535e27c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5O8\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "패딩 크기는 0(p=0)이다. 회전된 필터 $w^r$은 2칸씩 이동한다. 이동하는 양은 **스트라이드**(stride)라고 하며, 합성곱의 하이퍼파라미터이다. 스트라이드는 입력 벡터의 크기보다 작은 양수값이어야 한다."
      ],
      "metadata": {
        "id": "vYilWF7rTQjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 출력 특성 맵의 크기를 조절하기 위해 입력에 패딩\n",
        "  * 풀(full) 패딩\n",
        "    * 패딩 파라미터 p를 m-1로 설정.\n",
        "    * 출력 크기를 증가시키기 때문에 합성곱 신경망 구조에서는 거의 사용되지 않는다.\n",
        "  * 세임(same) 패딩\n",
        "    * 파딩 파라미터 p는 입력과 출력 크기가 동일해야 하기 때문에 필터 그기에 따라 결정\n",
        "    * 출력 크기가 입력 벡터 x와 같아야할 때 사용.\n",
        "  * 밸리드(valid) 패딩\n",
        "    * p=0\n",
        "    * 패딩 없음\n",
        "    "
      ],
      "metadata": {
        "id": "uFvyPnPBTw9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://git.io/JL5Ow', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "4jRZZpn8VM3F",
        "outputId": "8292baa4-cd4a-472e-b6bf-72dee474ab6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5Ow\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 신경망에서 가장 많이 사용되는 패딩 방법은 **세임** 패딩이다. \n",
        "\n",
        "* 세임 패딩 장점: **벡터 크기를 유지**시킨다는 것이다.\n",
        "\n",
        "컴퓨터 비전 분야의 이미지 관련 작이라면 입력 이미지의 높이와 너비가 유지된다. 이 때문에 네트워크 구조를 설계하기 쉽다.\n",
        "\n",
        "* 밸리드 패딩 단점: 신경망에 층이 추가될수록 점진적으로 텐서 크기가 줄어든다.\n",
        "    * 신경망 성능을 나쁘게 만들 수 있다.\n",
        "\n",
        "실전에서는 세임 패딩으로 너비와 높이를 유지시키고 풀링에서 크기를 감소시킨다. 풀 패딩은 입력보다 출력 크기를 증가시키므로 경계 부분의 영향을 최소화하는 것이 중요한 신호 처리 애플리케이션에서 보통 사용된다."
      ],
      "metadata": {
        "id": "XiLZu2FoVjLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 합성곱 출력 크기 계산\n",
        "    * 입력 벡터 위를 필터 w가 이동하는 전체 횟수\n",
        "    * n: 입력 벡터 크기\n",
        "    * m: 필터 크기\n",
        "    * p: 패딩\n",
        "    * s: 스트라이드\n",
        "    \n",
        "$$o = \\frac{n + 2p - m}{s} + 1$$\n",
        "\n",
        "$\\frac{n + 2p - m}{s}$의 소수점 아래 값 버림."
      ],
      "metadata": {
        "id": "5cpje3FlWVxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "rir0oF37X2TV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원 합성곱 계산\n",
        "def conv1d(x, w, p=0, s=1):\n",
        "    w_rot = np.array(w[::-1])\n",
        "    x_padded = np.array(x)\n",
        "    if p > 0:\n",
        "        zero_pad = np.zeros(shape=p)\n",
        "        x_padded = np.concatenate(\n",
        "            [zero_pad, x_padded, zero_pad])\n",
        "    res = []\n",
        "    for i in range(0, int((len(x_padded) - len(w_rot)) / s) + 1, s):\n",
        "        res.append(np.sum(x_padded[i:i+w_rot.shape[0]] * w_rot))\n",
        "    return np.array(res)\n",
        "\n",
        "# 테스트\n",
        "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
        "w = [1, 0, 3, 1, 2]\n",
        "\n",
        "print('Conv1d 구현:',\n",
        "      conv1d(x, w, p=2, s=1))\n",
        "\n",
        "print('넘파이 결과:',\n",
        "      np.convolve(x, w, mode='same')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzUBnZBgXEjV",
        "outputId": "124f75dc-4713-417b-da41-f0fd4d254ae0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1d 구현: [ 5. 14. 16. 26. 24. 34. 19. 22.]\n",
            "넘파이 결과: [ 5 14 16 26 24 34 19 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2D 이산 합성곱 수행\n"
      ],
      "metadata": {
        "id": "yGZ1_6CaY188"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 행렬 크기 = 8 * 8\n",
        "# 커널 크기 = 3 * 3\n",
        "# 입력 행렬이 p=1로 제로 패딩. => 2D 합성곱은 8 * 8 크기의 출력을 만듬\n",
        "Image(url='https://git.io/JL5OP', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "ELOyECBjZCW1",
        "outputId": "6c13f137-99bb-492c-fc68-e06862b1338f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5OP\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 p = (1, 1)\n",
        "# 스트라이드 s = (2, 2)\n",
        "# 입력 행렬 X 크기 = 3 * 3 -> 입력 행렬의 네 면에 0이 한 줄씩 추가(패딩)되어 X_padded 크기 = 5 * 5\n",
        "# 커널 행렬 W 크기 = 3 * 3\n",
        "Image(url='https://git.io/JL5OD', width=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "MXzEjxdAZfL1",
        "outputId": "2ec0e7a6-1c34-47f8-e7c1-52463caad952"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5OD\" width=\"600\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# W 뒤집기 -> W[::-1, ::-1]\n",
        "# X_padded를 따라 슬라이딩 윈도우처럼 역전된 필터를 이동하면서 원소별 곱의 합 계산\n",
        "# 결과 Y는 2 * 2 크기 행렬\n",
        "Image(url='https://git.io/JL5OS', width=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "TShibJQIaY-t",
        "outputId": "c6fab79e-ed77-4d50-8be4-dfd38d67735c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5OS\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D 합성곱\n",
        "import scipy.signal # 2D 합성곱을 계산할 수 있는 scipy.signal.convolve2d 함수 제공\n",
        "\n",
        "def conv2d(X, W, p=(0, 0), s=(1, 1)):\n",
        "    W_rot = np.array(W)[::-1, ::-1]\n",
        "    X_orig = np.array(X)\n",
        "    n1 = X_orig.shape[0] + 2 * p[0]\n",
        "    n2 = X_orig.shape[1] + 2 * p[1]\n",
        "    X_padded = np.zeros(shape=(n1, n2))\n",
        "    X_padded[p[0]:p[0]+X_orig.shape[0],\n",
        "             p[1]:p[1]+X_orig.shape[1]] = X_orig\n",
        "    res = []\n",
        "    for i in range(0, int((X_padded.shape[0] - W_rot.shape[0]) / s[0])+1, s[0]):\n",
        "        res.append([])\n",
        "        for j in range(0, int((X_padded.shape[1] - W_rot.shape[1]) / s[1])+1, s[1]):\n",
        "            X_sub = X_padded[i:i+W_rot.shape[0], j:j+W_rot.shape[1]]\n",
        "            res[-1].append(np.sum(X_sub * W_rot))\n",
        "    return np.array(res)\n",
        "\n",
        "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
        "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
        "\n",
        "print('Conv2d 구현:\\n',\n",
        "    conv2d(X, W, p=(1, 1), s=(1, 1)))\n",
        "\n",
        "\n",
        "print('싸이파이 결과:\\n',\n",
        "    scipy.signal.convolve2d(X, W, mode='same'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu51YAmxa0r0",
        "outputId": "907a6499-b03b-4878-9b27-0950c2666580"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d 구현:\n",
            " [[11. 25. 32. 13.]\n",
            " [19. 25. 24. 13.]\n",
            " [13. 28. 25. 17.]\n",
            " [11. 17. 14.  9.]]\n",
            "싸이파이 결과:\n",
            " [[11 25 32 13]\n",
            " [19 25 24 13]\n",
            " [13 28 25 17]\n",
            " [11 17 14  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.1.3 서브샘플링\n",
        "* 전형적인 두 종류의 풀링 연산으로 합성곱 신경망에 적용된다.\n",
        "    * 최대 풀링(max-pooling): 이웃한 픽셀에서 최댓값 계산\n",
        "    * 평균 풀링(mean-pooling 또는 average-pooling): 이웃한 픽셀에서 픽셀 평균 계산\n",
        "\n",
        "* 풀링 층은 보통 $P_{n1*n2}$ 로 표시\n",
        "    * 아래 첨자는 최댓값과 평균 연산이 수행되는 이웃한 픽셀 크기\n",
        "        * 차원별로 인접 픽셀 개수\n",
        "    * 이웃 픽셀 개수를 풀링 크기라고 한다."
      ],
      "metadata": {
        "id": "bQ1JgaxOciJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 풀링과 평균 풀링\n",
        "Image(url='https://git.io/JL5OH', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "n9fMBBSerJAO",
        "outputId": "0875a0b1-8d7b-46f9-96db-18614268adbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5OH\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 풀링의 장점\n",
        "    1. 풀링(최대 풀링)은 **지역 불변성**을 만든다. 국부적인 작은 변화가 최대 풀링의 결과를 바꾸지 못한다는 의미. 결국 입력 데이터에 있는 **잡음에 조금 더 안정**적인 특성을 생성한다.\n",
        "    2. 풀링은 특성 크기를 줄이므로 계산 효율성을 높인다. 또 특성 개수가 줄어들면 과대적합도 감소된다.\n",
        "\n",
        "* 겹치는 풀링 vs 겹치지 않는 풀링\n",
        "    * 전통적으로 풀링은 겹치지 않는다고 가정한다.\n",
        "        * 풀링이 겹치지 않도록 수행되기 때문에 일반적으로 스트라이드 크기를 풀링 크기와 같게 설정한다.\n",
        "        * ex, 겹치지 않는 풀링 층 P_n1*n2의 스트라이드 s는 (n1, n2)이다.\n",
        "    * 스트라이드가 풀링 크기보다 작으면 겹쳐서 풀링이 일어난다."
      ],
      "metadata": {
        "id": "Ak5lJ3akrQvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15.2 기본 구성 요소를 사용하여 심층 합성곱 신경망 구성\n",
        "* 합성곱 연산 Z = W * X + b\n",
        "    * X는 높이 * 너비의 픽셀을 나타내는 행렬\n",
        "    * 은닉 유닛의 활성화 출력 A = Φ(Z)를 얻기 위해 활성화 함수에 입력으로 전달.\n",
        "        * Φ: 활성화 함수\n",
        "\n",
        "### 15.2.1 여러 개의 입력 또는 컬러 채널 다루기\n",
        "합성곱 층의 입력 샘플에는 N1 * N2 차원(ex, 이미지의 높이와 너비 픽셀)인 하나의 2D 배열 또는 행렬이 포함될 수 있다. 이런 N1 * N2 행렬을 **채널**이라고 한다.\n",
        "\n",
        "합성곱 층은 랭크 3 텐서를 입력으로 한다. 즉 , $X_{N_{1}*N_{2}*C_{in}}$을 사용. 여기서 $C_{m}$은 입력 채널 크기이다. RGB 모드인 컬러일 경우 $C_{in}$=3이다. 그레이스케일(grayscale)인 흑백일 경우 $C_{in}$=1이다."
      ],
      "metadata": {
        "id": "WoDmSGdRuF2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 다운로드\n",
        "!wget https://git.io/JL5Ob -O example-image.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqeWy78OxOZv",
        "outputId": "8f90b5fe-f1e7-42a7-9bb2-454268576217"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-10 04:49:41--  https://git.io/JL5Ob\n",
            "Resolving git.io (git.io)... 52.204.242.176, 18.205.36.100, 54.157.58.70, ...\n",
            "Connecting to git.io (git.io)|52.204.242.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch15/example-image.png [following]\n",
            "--2022-02-10 04:49:42--  https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch15/example-image.png\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch15/example-image.png [following]\n",
            "--2022-02-10 04:49:43--  https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch15/example-image.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22283 (22K) [image/png]\n",
            "Saving to: ‘example-image.png’\n",
            "\n",
            "example-image.png   100%[===================>]  21.76K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-02-10 04:49:43 (9.78 MB/s) - ‘example-image.png’ saved [22283/22283]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지를 다룰 때 메모리 절약을 위해 16비트, 32비트, 64비트 정수 타입 대신 uint8(부호 없는 8비트 정수) 데이터 타입의 넘파이 배열로 이미지를 읽을 수 있다.\n",
        "\n",
        "부호 없는 8비트 정수는 [0, 255] 사이 값을 저장할 수 있는데 RGB 이미지의 픽셀 정보도 같은 범위이므로 충분하다."
      ],
      "metadata": {
        "id": "Y74JeDnSx0aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파일 읽기 - tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "img_raw = tf.io.read_file('example-image.png')\n",
        "img = tf.image.decode_image(img_raw)\n",
        "print('이미지 크기:', img.shape)\n",
        "print('채널 개수:', img.shape[2])\n",
        "print('이미지 데이터 타입:', img.dtype)\n",
        "print(img[100:102, 100:102, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uVkFNy6xR69",
        "outputId": "2e8ede54-ec8f-41f4-9c9d-7c4ff18f7aef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 크기: (252, 221, 3)\n",
            "채널 개수: 3\n",
            "이미지 데이터 타입: <dtype: 'uint8'>\n",
            "tf.Tensor(\n",
            "[[[179 134 110]\n",
            "  [182 136 112]]\n",
            "\n",
            " [[180 135 111]\n",
            "  [182 137 113]]], shape=(2, 2, 3), dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파일 읽기 - imageio\n",
        "import imageio\n",
        "\n",
        "img = imageio.imread('example-image.png')\n",
        "print('이미지 크기:', img.shape)\n",
        "print('채널 개수:', img.shape[2])\n",
        "print('이미지 데이터 타입:', img.dtype)\n",
        "print(img[100:102, 100:102, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV1iBtVrylXu",
        "outputId": "d3b3859b-02f3-42ce-d2d4-207bb98fe661"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 크기: (252, 221, 3)\n",
            "채널 개수: 3\n",
            "이미지 데이터 타입: uint8\n",
            "[[[179 134 110]\n",
            "  [182 136 112]]\n",
            "\n",
            " [[180 135 111]\n",
            "  [182 137 113]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN 입력을 위한 흑백 이미지의 랭크"
      ],
      "metadata": {
        "id": "CEQ0tjrtzMJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://git.io/JL5Op -O example-image-gray.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNDkmt-_zKbv",
        "outputId": "849574ff-b3a6-4358-b2e1-6726fd9ef9a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-10 04:49:43--  https://git.io/JL5Op\n",
            "Resolving git.io (git.io)... 52.204.242.176, 18.205.36.100, 54.157.58.70, ...\n",
            "Connecting to git.io (git.io)|52.204.242.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch15/example-image-gray.png [following]\n",
            "--2022-02-10 04:49:44--  https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch15/example-image-gray.png\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch15/example-image-gray.png [following]\n",
            "--2022-02-10 04:49:45--  https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch15/example-image-gray.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8501 (8.3K) [image/png]\n",
            "Saving to: ‘example-image-gray.png’\n",
            "\n",
            "example-image-gray. 100%[===================>]   8.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-10 04:49:45 (51.1 MB/s) - ‘example-image-gray.png’ saved [8501/8501]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_raw = tf.io.read_file('example-image-gray.png')\n",
        "img = tf.image.decode_image(img_raw)\n",
        "tf.print('랭크:', tf.rank(img))\n",
        "tf.print('크기:', img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBPXy5QrzQwm",
        "outputId": "51465c7b-e4fb-4c98-e55a-f718ba6ec5f5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랭크: 3\n",
            "크기: TensorShape([252, 221, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = imageio.imread('example-image-gray.png')\n",
        "tf.print('랭크:', tf.rank(img))\n",
        "tf.print('크기:', img.shape)\n",
        "\n",
        "img_reshaped = tf.reshape(img, (img.shape[0], img.shape[1], 1))\n",
        "tf.print('새로운 크기:', img_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn84ChS8zSWo",
        "outputId": "69fa95ce-1c6c-4fc4-8980-64c314f0c051"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랭크: 2\n",
            "크기: (252, 221)\n",
            "새로운 크기: TensorShape([252, 221, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "보통 CNN의 합성곱 층은 하나 이상의 특성 맵(h)을 만든다. 여러 개의 특성 맵을 사용하면 커널 텐서는 height * width * $C_{in}$ * $C_{out}$으로 4차원이 된다. 높이와 너비는 커널의 크기이고 $C_{in}$은 입력 채널의 개수, $C_{out}$은 출력 특성 맵의 개수이다."
      ],
      "metadata": {
        "id": "IKhKMffpzriN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.2.2 드롭아웃으로 신경망 규제\n",
        "* 네트워크의 크기에 대한 문제를 해결하는 방법\n",
        "    1. 훈련 데이터셋에서 잘 동작하도록 비교적 큰 용량의 네트워크를 구축(실제로 필요한 것보다 좀 더 큰 용량을 선택)\n",
        "    2. 과대적합을 막기 위해 한 개 이상의 규제 방법을 적용하여 별도의 테스트 데이터셋 같은 새로운 데이터에서 일반화 성능 높임\n",
        "\n"
      ],
      "metadata": {
        "id": "_Yranw-00wKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L2 규제\n",
        "from tensorflow import keras\n",
        "conv_layer = keras.layers.Conv2D(\n",
        "    filters=16,\n",
        "    kernel_size=(3, 3),\n",
        "    kernel_regularizer=keras.regularizers.l2(0.001))\n",
        "fc_layer = keras.layers.Dense(\n",
        "    units=16,\n",
        "    kernel_regularizer=keras.regularizers.l2(0.001))"
      ],
      "metadata": {
        "id": "pCCTMT2s2kTF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 드롭아웃(dropout)\n",
        "    * 보통 뒤쪽 층의 은닉 유닛에 적용.\n",
        "    * 신경망을 훈련하는 동안 반복마다 은닉 유닛의 일부가 확률 P_drop만큼 랜덤하게 드롭아웃 된다.\n",
        "    * 드롭아웃 확률은 사용자가 지정.\n",
        "        * 가장 많이 사용하는 값은 p=0.5이다.\n",
        "    * 입력 뉴런의 일부를 드롭아웃할 때 없어진(드롭아웃된) 뉴런을 보상하기 위해 남은 뉴런에 연결된 가중치 값을 크게 한다.\n",
        "    * 랜덤한 드롭아웃의 영향으로 네트워크는 데이터에서 여분의 표현을 학습한다.\n",
        "        * 네트워크가 일부 은닉 유닛의 활성화 값에 의존할 수 없다.\n",
        "            * 훈련과정에서 언제든지 은닉 유닛이 꺼질 수 있기 때문\n",
        "        * 네트워크가 데이터에서 더 일반적으로 안정적인 패턴을 학습하게 만든다.\n",
        "    * 랜덤한 드롭아웃은 과대적합을 효과적으로 방지."
      ],
      "metadata": {
        "id": "TkvcGvxD3C9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 드롭아웃 예\n",
        "Image(url='https://git.io/JL5Oh', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "4cvdKAWn4Bge",
        "outputId": "ff8efd34-b381-4fd2-ec73-4cdcb3e3443e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL5Oh\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 단계에서만 유닛이 랜덤하게 꺼진다는 것이 중요. 평가(추론) 단계에서는 모든 유닛이 활성화되어야 한다.(즉, P_drop = 0, P_keep = 1)\n",
        "\n",
        "훈련과 예측 단계의 전체 활성화 값의 스케일을 맞추기 위해 활성화된 뉴런 출력이 적절히 조정되어야 한다.(ex, 훈련 시 드롭아웃 p=0.5일 때 테스트 시 활성 출력을 절반으로 낮춘다)\n",
        "\n",
        "실전에서 예측을 만들 때 활성화 값의 출력을 조정하는 것은 불편하기 때문에 텐서플로나 다른 라이브러리들은 훈련 단계의 활성화를 조정한다. 이런 방법을 **역 드롭아웃**이라 한다.\n",
        "\n",
        "드롭아웃은 앙상블 모델의 기하 평균이 훈련 과정에서 샘플링된 마지막(또는 최종) 모델의 예측에 1 / (1-p)를 곱하는 것으로 근사할 수 있다."
      ],
      "metadata": {
        "id": "48b--rUt4FJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.2.3 분류를 위한 손실 함수\n",
        "* 렐루와 같은 몇몇 활성화 함수는 모델에 비선형성을 더하기 위해 신경망의 중간(은닉)층에 주로 사용.\n",
        "    * (이진 분류일 경우) 시그모이드와 (다중 분류일 경우) 소프트맥스 같은 함수는 마지막 (출력)층에 추가되어 클래스 소속 롹률을 출력\n",
        "    * 시그모이드와 소프트맥스 활성화 함수가 출력층에 포함되지 않으면 모델은 클래스 소속 확률 대신 로짓을 계산할 것이다.\n",
        "\n",
        "* 분류 모델\n",
        " * **`BinaryCrossentropy()`**\n",
        "   * `from_logits=False` \n",
        "   * `from_logits=True`\n",
        "\n",
        " * **`CategoricalCrossentropy()`**\n",
        "   * `from_logits=False`\n",
        "   * `from_logits=True`\n",
        "   \n",
        " * **`SparseCategoricalCrossentropy()`**\n",
        "   * `from_logits=False`\n",
        "   * `from_logits=True`"
      ],
      "metadata": {
        "id": "49CTjJW_5ay2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 문제에 사용하는 손실 함수\n",
        "Image(url='https://git.io/JL53f', width=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Ui4H2G2K6vq3",
        "outputId": "0fcdcaa8-28c2-4697-b754-cfe085aef8e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://git.io/JL53f\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "클래스 소속 확률이 아니라 **로짓으로 크로스 엔트로피 손실을 계산하는 것이 수치상의 안정성 때문에 일반적으로 선호**된다. 손실 함수의 입력으로 로짓을 사용하고 `from_logits=True`로 지정하면 해당하는 텐서플로 함수는 훨씬 효율적인 구현을 사용하여 손실과 가중치에 대한 손실의 도함수를 계산한다. 로짓이 입력으로 제공되면 일부 수학 항을 소거할 수 있어 굳이 계산하지 않아도 되기 때문이다."
      ],
      "metadata": {
        "id": "TAGdlgz26_DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로짓이나 클래스 소속 확률이 손실 함수의 입력으로 주어졌을 때 세 개의 손실 함수를 사용하는 방법\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 이진 크로스 엔트로피\n",
        "bce_probas = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "bce_logits = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "logits = tf.constant([0.8])\n",
        "probas = tf.keras.activations.sigmoid(logits)\n",
        "\n",
        "print(\n",
        "    'BCE (확률): {:.4f}'.format(bce_probas(y_true=[1], y_pred=probas)),\n",
        "    '(로짓): {:.4f}'.format(bce_logits(y_true=[1], y_pred=logits)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1a4QS3W7pLG",
        "outputId": "556e7afe-7034-4fd6-b759-c5d59701d13d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCE (확률): 0.3711 (로짓): 0.3711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 범주형 크로스 엔트로피\n",
        "cce_probas = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "cce_logits = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "logits = tf.constant([[1.5, 0.8, 2.1]])\n",
        "probas = tf.keras.activations.softmax(logits)\n",
        "\n",
        "tf.print(\n",
        "    'CCE (확률): {:.4f}'.format(cce_probas(y_true=[[0, 0, 1]], y_pred=probas)),\n",
        "    '(로짓): {:.4f}'.format(cce_logits(y_true=[[0, 0, 1]], y_pred=logits)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad8qTTvU8h9m",
        "outputId": "d21e96d5-3d23-483a-aa4b-d6ebf5b368d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCE (확률): 0.5996 (로짓): 0.5996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 희소 범주형 크로스 엔트로피\n",
        "sp_cce_probas = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "sp_cce_logits = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "tf.print(\n",
        "    'Sparse CCE (확률): {:.4f}'.format(sp_cce_probas(y_true=[2], y_pred=probas)),\n",
        "    '(로짓): {:.4f}'.format(sp_cce_logits(y_true=[2], y_pred=logits)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8F5evQ38zdm",
        "outputId": "3852c63c-7228-4cb3-cdde-ba7350ba069c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse CCE (확률): 0.5996 (로짓): 0.5996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "가끔 샘플마다 두 개의 출력을 얻어 각 클래스에 대한 확률 (P[class=0] 대 P[calss=1])로 해석되기도 한다. 이런 경우 로지스틱 시그모이드 대신 소프르맥수 함수를 사용하여 출력을 정규화(즉, 합이 1이 되로곡)하는 것이 좋다. 이때는 범주형 크로스 엔트로피가 손실 함수로 적절."
      ],
      "metadata": {
        "id": "6DazdNqt9ZMG"
      }
    }
  ]
}